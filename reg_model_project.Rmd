---
title: "Linear Modeling and Prediction for Movies"
author: "David Kochar"
date: '`r Sys.Date()`'
output: 
  html_document: 
    keep_md: true
    highlight: pygments
    theme: spacelab
---

##Synopsis

This analysis performs exploratory data anlaysis and linear regression, modeling, and prediction with a data set of 651 randomly sampled movies. The movie data used in the analysis was sourced from IMDB and Rotten Tomatoes APIs.

## Setup

We will first prepare the workspace environment by setting global options.

### Set Global Options

```{r setupknitr}
#Install Knitr pckage if necessary and load Knitr library
list.of.packages <- c("knitr")
new.packages <-
list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
if (length(new.packages))
install.packages(new.packages, repos = "http://cran.us.r-project.org")
suppressWarnings (suppressMessages (library (knitr)))
knitr::opts_chunk$set(
fig.width = 8,
fig.height = 4,
fig.path = 'figures/DataAnalysisProject_',
echo = TRUE,
warning = FALSE,
message = FALSE
)
#Clear variables
rm (list = ls (all = TRUE))
#Get and set working directory
setwd (getwd ())
```

### Load Packages

Install and load required libraries if neccessary.

```{r load-packages}
#Check installed status of requried packages, and install if necessary
list.of.packages <-
  c("statsr", "dplyr", "ggplot2", "kableExtra", "olsrr", "lmtest", "car")
new.packages <-
  list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
if (length(new.packages))
  install.packages(new.packages, repos = "http://cran.us.r-project.org")
suppressWarnings (suppressMessages (library (statsr)))
suppressWarnings (suppressMessages (library (dplyr)))
suppressWarnings (suppressMessages (library (ggplot2)))
suppressWarnings (suppressMessages (library (kableExtra)))
suppressWarnings (suppressMessages (library (olsrr)))
suppressWarnings (suppressMessages (library (lmtest)))
suppressWarnings (suppressMessages (library (car)))
```

### Load data

Load the data set.

```{r load-data}
load ( url ("https://d18ky98rnyall9.cloudfront.net/_e1fe0c85abec6f73c72d73926884eaca_movies.Rdata?Expires=1516924800&Signature=WUuGqHLm1BK2nWJPFSb~ONIiNylTRh4amRdLaX0bWK8T1daAC~XVI~Kw4rHHXsWMMp2pa2HLTbEUhk4sW3TA1MNvtocSihOxm33Dc~oEJuQ7alE0Wmm4PLyTGi~XUvNejiyoVpugdfuDphurmxsEBtF2xo59jrRRjjY7XjfJIQs_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"))
```



* * *

## Part 1: Data

According to the project's code book, the observations in the "Movies" data set were randomly sampled from IMDB and Rotten Tomatoes APIs. For the sake of the analysis, we will assume the sampling method used was simple random sampling.

Since simple random sampling was used, we know that each population observation has an equal chance of being selected. Thus, we can infer generalizability about the "Movies" data set. Note that we cannot infer causality becase random assignment of the observations was not used.

* * *

## Part 2: Research question

We will research the association and predictive value between the response variable "Audience Score on Rotten Tomatoes," and multiple explanatory variables to build a multiple linear regression model. Variable selection criteria will be covered in Part 4: Modeling. Note the explanatory variables used in the model were selected based on their contextual relevance, and we won't be excluding variables upfront other than those that have obviously no value.

The "Audience score on Rotten Tomatoes" variable as a response is of interest because Rotten Tomatoes is more of a "popularity" score generator based on likes and dislikes, and as percentage score, this metric is easily digested. So, as a very simplified and condensed metric, uncovering any meaningful relationships will be interesting.


* * *

## Part 3: Exploratory data analysis

For our Exploratory Data Analysis, let's first get familiar with our response variable, "Audience Score on Rotten Tomatoes," by determining its distribution and summary statistics.

Using a histogram, we will survey the normality.

```{r audiencescore-histogram}
ggplot(data = movies, aes(movies$audience_score)) +
  geom_histogram(
    breaks = seq(0, 100, by = 10),
    col = "white",
    fill = "blue",
    alpha = 1
  ) +
  scale_x_continuous(
    expand = c(0, 0),
    limits = c(0, 100),
    breaks = seq(0, 100, by = 10)
  ) +
  scale_y_continuous(
    expand = c(0, 0),
    limits = c(0, 150),
    breaks = seq(0, 150, by = 25)
  ) +
  labs(title = "Histogram for Audience Score on Rotten Tomatoes") +
  labs(x = "Audience Score", y = "Count")
```

There data is slightly skewed to the left, suggesting Rotten Tomatoes reviews tend to be more positive. Let's calculate summary statistics.

```{r audiencescore-summarystats}
#Compute summary stats
AudienceScoreSummary <- movies %>%
select (audience_score) %>%
filter(audience_score != "NA") %>%
summarise (
Total = n (),
MinAudienceScore = min(audience_score, na.rm = TRUE),
MaxAudienceScore = max(audience_score, na.rm = TRUE),
AverageAudienceScore = mean(audience_score, na.rm = TRUE),
MedianAudienceScore = median(audience_score, na.rm = TRUE),
AudienceScoreIQR = IQR(audience_score, na.rm = TRUE)
)

#Create summary table
suppressWarnings (suppressMessages (library (kableExtra)))
AudienceScoreSummary %>%
kable("html") %>%
kable_styling()
```


We see the median score is higher than the mean score, confirming the left skewness. Now, let's compare the distribution of the rating on IMDB to see any potential bias. We will again use a histogram to survey the normality.

```{r imdbrating-histogram}
ggplot(data = movies, aes(movies$imdb_rating)) +
  geom_histogram(
    breaks = seq(0, 10, by = 1),
    col = "white",
    fill = "blue",
    alpha = 1
  ) +
  scale_x_continuous(
    expand = c(0, 0),
    limits = c(0, 10),
    breaks = seq(0, 10, by = 1)
  ) +
  scale_y_continuous(
    expand = c(0, 0),
    limits = c(0, 250),
    breaks = seq(0, 250, by = 25)
  ) +
  labs(title = "Histogram for IMDB Rating") +
  labs(x = "IMDB Rating", y = "Count")
```


There data is also slightly skewed to the left, suggesting IMDB ratings tend to be more positive. Let's calculate summary statistics.

```{r IMDBRating-summarystats}
#Compute summary stats
IMDBRatingSummary <- movies %>%
  select (imdb_rating) %>%
  filter(imdb_rating != "NA") %>%
  summarise (
  Total = n (),
  MinIMDBRating = min(imdb_rating, na.rm = TRUE),
  MaxIMDBRating = max(imdb_rating, na.rm = TRUE),
  AverageIMDBRating = mean(imdb_rating, na.rm = TRUE),
  MedianIMDBRating = median(imdb_rating, na.rm = TRUE),
  IMDBRatingIQR = IQR(imdb_rating, na.rm = TRUE)
  )

#Create summary table
suppressWarnings (suppressMessages (library (kableExtra)))
IMDBRatingSummary %>%
  kable("html") %>%
  kable_styling()
```


Again, we see the median score is higher than the mean score, confirming the left skewness of the IMDB Ratings. At this point, we want to call out potential bias in the sample and its potential effects on generalizability.

However, this bias may disappear in a multi-variate view. Let's breakdown our Rotten Tomatoes Audience Score by MPAA rating.

```{r AudienceScore-RatingBoxplots}
ggplot(data = subset(movies, !is.na(mpaa_rating) &
                       !is.na(audience_score)),
                       aes(x = mpaa_rating, y = audience_score)) +
                       geom_boxplot(fill = "#56B4E9") +
                       labs(title = "Rotten Tomatoes Audience Score by MPAA Rating", x = "MPAA Rating", y = "Audience Score")
```

We can see that "Unrated" movies have overwhelmingly positive reviews with little variation, and PG-13 movies have the lowest median score with much variability. To get a more detailed view of skewness, let's look at a quantile-quantile plot.

```{r AudienceScore-MPAAQuantQuant}
qplot(
  sample = audience_score,
  data = subset(movies,!is.na(mpaa_rating) &
                  !is.na(audience_score)),
  color = mpaa_rating,
  shape = mpaa_rating
)
```

Left-skewness is definitive except for the PG-13 rating. Let's see what the summary statistics say.

```{r audiencescore-mpaasummarystats}
#Compute summary stats
AudienceScoreSummaryMPAA <- movies %>%
  select (mpaa_rating, audience_score) %>%
  filter(audience_score != "NA") %>%
  group_by (mpaa_rating) %>%
  summarise (
    Total = n (),
    MinAudienceScore = min(audience_score, na.rm = TRUE),
    MaxAudienceScore = max(audience_score, na.rm = TRUE),
    AverageAudienceScore = mean(audience_score, na.rm = TRUE),
    MedianAudienceScore = median(audience_score, na.rm = TRUE),
    AudienceScoreIQR = IQR(audience_score, na.rm = TRUE)
  ) %>%
  arrange (desc(AverageAudienceScore))

#Create summary table
suppressWarnings (suppressMessages (library (kableExtra)))
AudienceScoreSummaryMPAA %>%
  kable("html") %>%
  kable_styling()
```

We can conclude that left-skenewness is pervasive for almost all of the MPAA ratings except the normally distributed PG-13 rating.

As an additional angle on multi-variate analysis of skewness, we will look at the movie genre and repeat our set of visuals and summary stats.

```{r AudienceScore-GenreBoxplots}
ggplot(data = subset(movies,!is.na(genre) &
                       !is.na(audience_score)),
                       aes(x = genre, y = audience_score)) +
                       geom_boxplot(fill = "#56B4E9") +
                       labs(title = "Rotten Tomatoes Audience Score by Genre", x = "Genre", y = "Audience Score") +
                       theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Genre variability is incredibly diverse. We can see that a movie's rating is definitely affected by its genre, where documentaries fare much better than action movies. This revelation begs the question of significance between genres, which we may wan to address in additional analysis. Let's look at the quantile-quantile plot.

```{r AudienceScore-RatingQuantQuant}
p <- qplot(
  sample = audience_score,
  data = subset(movies, !is.na(genre) &
  !is.na(audience_score)),
  color = genre,
  shape = genre
  )
  p + scale_shape_manual(values = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
```

The "Documentary" and "Musical & Performing Arts" genres are notable examples of left-skew. Now for the summary stats.

```{r audiencescore-genreummarystats}
#Compute summary stats
AudienceScoreSummaryGenre <- movies %>%
  select (genre, audience_score) %>%
  filter(audience_score != "NA") %>%
  group_by (genre) %>%
  summarise (
    Total = n (),
    MinAudienceScore = min(audience_score, na.rm = TRUE),
    MaxAudienceScore = max(audience_score, na.rm = TRUE),
    AverageAudienceScore = mean(audience_score, na.rm = TRUE),
    MedianAudienceScore = median(audience_score, na.rm = TRUE),
    AudienceScoreIQR = IQR(audience_score, na.rm = TRUE)
  ) %>%
  arrange (desc(AverageAudienceScore))

#Create summary table
suppressWarnings (suppressMessages (library (kableExtra)))
AudienceScoreSummaryGenre %>%
  kable("html") %>%
  kable_styling()
```

The "Drama" genre had the highest number of observations, and also had the 4th largest mean Audience score. This is helping to shift our global average.

* * *

## Part 4: Modeling

As mentioned in Part 2, the "Audience Score on Rotten Tomatoes" (audience_score) is our dependent variable. The below explanatory variables will be excluded from modeling because in terms of dimensional richness, they offer no meaningful information gain or they add model noise because they are very high-cardinality (unique). For example, the "Link to Rotten Tomatoes page for the movie" variable would have virtually no model value due to its tangential nature and its high-cardinality - in other words, a URL has no domain context from a decision making perspective.

* Title of movie
* Studio that produced the movie
* Year the movie is released in theaters
* Day of the month the movie is released in theaters
* Year the movie is released on DVD
* Day of the month the movie is released on DVD
* Number of votes on IMDB
* Director of the movie
* First main actor/actress in the abridged cast of the movie
* Second main actor/actress in the abridged cast of the movie
* Third main actor/actress in the abridged cast of the movie
* Fourth main actor/actress in the abridged cast of the movie
* Fifth main actor/actress in the abridged cast of the movie
* Link to IMDB page for the movie
* Link to Rotten Tomatoes page for the movie

The below explanatory variables will be included in our modeling as they offer the most information gain potential and dimensional richness.

* Type of movie (Documentary, Feature Film, TV Movie)
* Critics score on Rotten Tomatoes
* Critics rating on Rotten Tomatoes (Certified Fresh, Fresh, Rotten)
* MPAA rating of the movie (G, PG, PG-13, R, Unrated)
* Genre of movie (Action & Adventure, Comedy, Documentary, Drama, Horror, Mystery & Suspense, Other)
* Month the movie is released in theaters
* Month the movie is released on DVD
* Rating on IMDB
* Runtime of movie (in minutes)
* Whether or not the movie was nominated for a best picture Oscar (no, yes)
* Whether or not the movie won a best picture Oscar (no, yes)
* Whether or not one of the main actors in the movie ever won an Oscar (no, yes)
* Whether or not one of the main actresses in the movie ever won an Oscar (no, yes)
* Whether or not the director of the movie ever won an Oscar (no, yes)
* Whether or not the movie is in the Top 200 Box Office list on BoxOfficeMojo (no, yes)

To build our mulitple linear regression model, we will use stepwise forward selection via the "ols_step_forward" function from the "olsrr" R package. The function will build the model from our set of explanatory variables by entering predictors based on p-values in a stepwise manner. The first variable to be added to the model is most the significant, and more variables are included until none of remaining variables are "significant" when added to the model.

Compared to stepwise backward selection, stepwise forward selection was used for its low resource overhead and thus ease of reproducibility. It is worth noting the forward selection key disadvantage, such that each addition of a new variable may undermine the significance of variables already in the model.

Let's run the model.

```{r audiencescore-model}
#create the list of predictor coefficients
MultiRegression1 <- lm(
  audience_score ~ title_type +
  genre +
  runtime +
  mpaa_rating +
  thtr_rel_month +
  dvd_rel_month +
  imdb_rating +
  critics_rating +
  critics_score +
  best_pic_nom +
  best_pic_win +
  best_actor_win +
  best_actress_win +
  best_dir_win +
  top200_box,
  data = movies
  )

#generate the multi-regression model  
ols_step_forward (MultiRegression1, details = TRUE)
```

Our model has selected the variables of IMDB Rating, Genre, and the Critics score on Rotten Tomatoes. Let's peform diagnostics to evaluate how well the model fits the data. We will use the standard diagnostic plot set of: 

* Residuals vs. Fitted Values Plot
* Quantile-Quantile (Q-Q) Plot
* Scale Location Plot
* Residuals vs. Leverage Plot

First, we need to generate a new model based on the stepwise forward selection.

```{r new-model}
#generate the new model
MultiRegression2 <- lm(
  audience_score ~ 
    imdb_rating +
    critics_score +
    genre,
  data = movies
)
```

Next, we create our plots.

```{r diagnostic-plots}
#plot diagnostics with the generated model
plot (MultiRegression2)
```

Now we can step through each plot to understand the diagnostic assessment.

* **Residuals vs. Fitted Values Plot**: There are no obvious patterns in the distribution. The points appear randomly distributed
* **Q-Q Plot**: Save for a few outliers in the upper right quadrant, our residuals show a very normal distribution
* **Scale Location Plot**: As with the Residuals vs. Fitted plot, there are no obvious patterns in the distribution. The points appear randomly distributed
* **Residuals vs. Leverage Plot**: We see that points 126, 348, and 302 have the greatest influence on the model


To verify our residuals vs. fitted values' heteroscedasticity, we will use a Breusch-Pagan Test and an NCV Test.

```{r BP-Test}
bptest (MultiRegression2)
ncvTest (MultiRegression2)
```

Since both tests have a p-value less than a significance level of 0.05, we can conclude heteroscedasticity exists.

To conclude our modeling section, we will provide the interpretation of the model coefficients. Here's a summary of the model.

```{r new-modelsummary}
summary (MultiRegression2)
```

Let's review our coefficients:

* **Intercept**: This is a model coefficient. When all explanatory variables are set to zero, the predicted Audience score on Rotten Tomatoes is -37.15275. This is meaningless because we cannot have a negative Audience Score
* **imdb_rating**: This is a model coefficient. Holding all other explanatory variables constant, for each 1 point increase in our IMDB Rating, the model predicts that our Audience Score will increase by 14.76 on average
* **genre**: This is a model coefficient. Note that our reference level for genre is "Action & Adventure" because it is not listed in the output. For the reference level, we would use "0" for all other genre levels to predict the Audience score. For all non-reference levels, we would use "1" for the level of interest and "0" for the other levels. So, all else constant, the model predicts that for each non-reference genre level the Audience score will be the level's coeffcient higher or lower
* **Std. Error**: The Standard Error represents the average amount the model coefficients differ from the actual average of the response variable
* **t value**: The t-value tells us the number of standard deviations the model coefficient estimate is from zero
* **Pr(>|t|)**: The p-value is probability of any value being equal to or larger than t

* * *

## Part 5: Prediction

At this point, we are ready to test the predictive ability of our multi-regession model. We will use the 2016 comedy film "Bad Santa 2" to predict the Rotten Tomatoes Audience Score. 

Using the URLs https://www.rottentomatoes.com/m/bad_santa_2 and http://www.imdb.com/title/tt1798603/?ref_=ttls_li_tt, we see that our Rotten Tomatoes Critics Score is 23%, and the IMDB rating is 5.6.

Using R's "predict" function, let's run our model.

```{r new-modelprediction}
#Create a data frame for the variables we will pass to the model
NewMovie <- data.frame(imdb_rating = 5.6, critics_score = 23, genre = "Comedy" )
#Predict the Audience score with the provided variables
predict (MultiRegression2, NewMovie, interval="predict", level = 0.95)
```

With the provided variables, the predicted Audience Score is **49.16892** which is generous compared to the actual Audience Score of **34**.

The 95% prediction interval of the Audience Score for an IMDB Rating of 5.6, a Critic's Score of 23, and a genre of "Comedy" is between 29.76966 % and 68.56818 %. If we were to collect additional sample movie data sets, there is a 95% probability that our provided variables will generate a predicted value within the prediction interval.

Our prediction interval width is allowing for a high degree of accuracy, but it is not very precise because it spans almost 40 percentage points. If we are concerned with precision, we may want to select a narrower prediction interval or increase our sample size.


* * *

## Part 6: Conclusion

When looking at any ratings methodology, our desire is to see ratings that do not have inherent bias in so far that we don't have too many critical or complimentary reviews. Our exploratory data analysis indicates that our given sample may actually have a complimentary bias. Therefore, we need to be careful with any inference or modeling applications.

Despite a resulting simple model, additional mulitple regression techniques, such as backward selection, should also be entertained to check model convergence and help refine prediction. We would also want to investigate the sampling method and experiment with larger sample sizes to increase our prediction precision. It is assumed that the IMDB and Rotten Tomatoe APIs would not prohibit us from obtaining an adequately sized data set.